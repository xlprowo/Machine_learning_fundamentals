{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Fashion MINST classification with Pytorch.\n",
        "\n",
        "#### Objective:\n",
        "\n",
        "The following notebook consist of a convolutional neural network to classify the images of the Fashion MINST dataset. The purpose of this exercise is to get used to and explore Pytorch's ecosystem for Machine learning."
      ],
      "metadata": {
        "id": "V6wUCAC2lqib"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Import dataset and necessary libraries.\n",
        "\n",
        "The models used belong to the Pytorch ecosystem, however numpy and the dataset from keras do not belong to Pytorch but are used as part of the exercise.\n",
        "\n",
        "For the case of the dataset, it could have been imported from Pytorch but the dataset from  the keras library was used in order to practice preprocessing and data adjustments from other sources and avoid using a dataset directly provided by pytorch."
      ],
      "metadata": {
        "id": "4yoF8KH1rO-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import DataLoader\n",
        "from tensorflow.keras import datasets as dt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "3XXchMq1yBcJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test)= dt.fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "Bbn9U3YcyTHu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96e0d288-d59f-44e2-afce-748117fd51bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the dataset is downloaded a summary of its shape is displayed to confirm it is divided in training and test set."
      ],
      "metadata": {
        "id": "woo8RCeHxytj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.shape(x_train))\n",
        "print(np.shape(y_train))\n",
        "print(np.shape(x_test))\n",
        "print(np.shape(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSR_WlbyyaCb",
        "outputId": "f50a263b-36f1-47ca-d27d-0336002cd985"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(10000, 28, 28)\n",
            "(10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A dictionary object is created with the names of the clothes and their numerical reference to understand the outputs."
      ],
      "metadata": {
        "id": "k083M8CTUj3w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_classes= {0:\"T-shirt/top\",\n",
        "                1:\"Trouser\",\n",
        "                2:\"Pullover\",\n",
        "                3:\"Dress\",\n",
        "                4:\"Coat\",\n",
        "                5:\"Sandal\",\n",
        "                6:\"Shirt\",\n",
        "                7:\"Sneaker\",\n",
        "                8:\"Bag\",\n",
        "                9:\"Ankle boot\"}"
      ],
      "metadata": {
        "id": "aCWbLq9_yjpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing the dataset.\n",
        "\n",
        "In order to have a useful dataset for Pytorch a Dataset class is implemented with three necessary functions: __init__, __len__, and __getitem__. The purpose of this class is to create the dataset object that returns the sample and label and perform the necessary transformations.\n",
        "\n",
        "The data object will only apply one transformation, it will change the data of the samples to a tensor. It's important to remember that Pytorch works with tensors."
      ],
      "metadata": {
        "id": "rOZSp0UoXEy4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class dataset1(Dataset):\n",
        "    def __init__(self, labels, X, transform=None):\n",
        "        self.y= labels\n",
        "        self.X = X\n",
        "        self.transform = transform\n",
        "\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.X[idx]\n",
        "        label = self.y[idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        label = torch.tensor(label)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "xgWibnnEXGaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset object is created using the raw data that was downloaded from Keras and divided in three; one part as a training set, the second part as an evaluation dataset and finally a third division to test the model."
      ],
      "metadata": {
        "id": "OXMdMUTkJWLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_training = dataset1(labels=y_train, X=x_train, transform= transforms.ToTensor())\n",
        "data_eval = dataset1(labels=y_test[:3000], X=x_test[:3000], transform=transforms.ToTensor())\n",
        "data_testing =dataset1(labels=y_test[3000:], X=x_test[3000:], transform=transforms.ToTensor())"
      ],
      "metadata": {
        "id": "gQ3G2SMXu7Pm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### An example of the first sample converted to a tensor.\n",
        "\n",
        "It is interesting to see that the transformation not only turns the image into a tensor but it also \"normalizes\" the inputs between 0 and 1. This shows the capabilities of pytorch for handling, preprocessing and transforming data."
      ],
      "metadata": {
        "id": "jwFM2QKNNZu-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_training[0]"
      ],
      "metadata": {
        "id": "_0XoEJ3vkprZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5e168e6-8408-4002-a4bf-41f757479def"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:152: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
            "  img = torch.from_numpy(pic.transpose((2, 0, 1))).contiguous()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0510,\n",
              "           0.2863, 0.0000, 0.0000, 0.0039, 0.0157, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0039, 0.0039, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.1412, 0.5333,\n",
              "           0.4980, 0.2431, 0.2118, 0.0000, 0.0000, 0.0000, 0.0039, 0.0118,\n",
              "           0.0157, 0.0000, 0.0000, 0.0118],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0235, 0.0000, 0.4000, 0.8000,\n",
              "           0.6902, 0.5255, 0.5647, 0.4824, 0.0902, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0471, 0.0392, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6078, 0.9255,\n",
              "           0.8118, 0.6980, 0.4196, 0.6118, 0.6314, 0.4275, 0.2510, 0.0902,\n",
              "           0.3020, 0.5098, 0.2824, 0.0588],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.2706, 0.8118, 0.8745,\n",
              "           0.8549, 0.8471, 0.8471, 0.6392, 0.4980, 0.4745, 0.4784, 0.5725,\n",
              "           0.5529, 0.3451, 0.6745, 0.2588],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0039, 0.0039, 0.0039, 0.0000, 0.7843, 0.9098, 0.9098,\n",
              "           0.9137, 0.8980, 0.8745, 0.8745, 0.8431, 0.8353, 0.6431, 0.4980,\n",
              "           0.4824, 0.7686, 0.8980, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7176, 0.8824, 0.8471,\n",
              "           0.8745, 0.8941, 0.9216, 0.8902, 0.8784, 0.8706, 0.8784, 0.8667,\n",
              "           0.8745, 0.9608, 0.6784, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7569, 0.8941, 0.8549,\n",
              "           0.8353, 0.7765, 0.7059, 0.8314, 0.8235, 0.8275, 0.8353, 0.8745,\n",
              "           0.8627, 0.9529, 0.7922, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0039, 0.0118, 0.0000, 0.0471, 0.8588, 0.8627, 0.8314,\n",
              "           0.8549, 0.7529, 0.6627, 0.8902, 0.8157, 0.8549, 0.8784, 0.8314,\n",
              "           0.8863, 0.7725, 0.8196, 0.2039],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0235, 0.0000, 0.3882, 0.9569, 0.8706, 0.8627,\n",
              "           0.8549, 0.7961, 0.7765, 0.8667, 0.8431, 0.8353, 0.8706, 0.8627,\n",
              "           0.9608, 0.4667, 0.6549, 0.2196],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0157, 0.0000, 0.0000, 0.2157, 0.9255, 0.8941, 0.9020,\n",
              "           0.8941, 0.9412, 0.9098, 0.8353, 0.8549, 0.8745, 0.9176, 0.8510,\n",
              "           0.8510, 0.8196, 0.3608, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0039, 0.0157, 0.0235, 0.0275, 0.0078, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.9294, 0.8863, 0.8510, 0.8745,\n",
              "           0.8706, 0.8588, 0.8706, 0.8667, 0.8471, 0.8745, 0.8980, 0.8431,\n",
              "           0.8549, 1.0000, 0.3020, 0.0000],\n",
              "          [0.0000, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.2431, 0.5686, 0.8000, 0.8941, 0.8118, 0.8353, 0.8667,\n",
              "           0.8549, 0.8157, 0.8275, 0.8549, 0.8784, 0.8745, 0.8588, 0.8431,\n",
              "           0.8784, 0.9569, 0.6235, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.1725, 0.3216, 0.4196,\n",
              "           0.7412, 0.8941, 0.8627, 0.8706, 0.8510, 0.8863, 0.7843, 0.8039,\n",
              "           0.8275, 0.9020, 0.8784, 0.9176, 0.6902, 0.7373, 0.9804, 0.9725,\n",
              "           0.9137, 0.9333, 0.8431, 0.0000],\n",
              "          [0.0000, 0.2235, 0.7333, 0.8157, 0.8784, 0.8667, 0.8784, 0.8157,\n",
              "           0.8000, 0.8392, 0.8157, 0.8196, 0.7843, 0.6235, 0.9608, 0.7569,\n",
              "           0.8078, 0.8745, 1.0000, 1.0000, 0.8667, 0.9176, 0.8667, 0.8275,\n",
              "           0.8627, 0.9098, 0.9647, 0.0000],\n",
              "          [0.0118, 0.7922, 0.8941, 0.8784, 0.8667, 0.8275, 0.8275, 0.8392,\n",
              "           0.8039, 0.8039, 0.8039, 0.8627, 0.9412, 0.3137, 0.5882, 1.0000,\n",
              "           0.8980, 0.8667, 0.7373, 0.6039, 0.7490, 0.8235, 0.8000, 0.8196,\n",
              "           0.8706, 0.8941, 0.8824, 0.0000],\n",
              "          [0.3843, 0.9137, 0.7765, 0.8235, 0.8706, 0.8980, 0.8980, 0.9176,\n",
              "           0.9765, 0.8627, 0.7608, 0.8431, 0.8510, 0.9451, 0.2549, 0.2863,\n",
              "           0.4157, 0.4588, 0.6588, 0.8588, 0.8667, 0.8431, 0.8510, 0.8745,\n",
              "           0.8745, 0.8784, 0.8980, 0.1137],\n",
              "          [0.2941, 0.8000, 0.8314, 0.8000, 0.7569, 0.8039, 0.8275, 0.8824,\n",
              "           0.8471, 0.7255, 0.7725, 0.8078, 0.7765, 0.8353, 0.9412, 0.7647,\n",
              "           0.8902, 0.9608, 0.9373, 0.8745, 0.8549, 0.8314, 0.8196, 0.8706,\n",
              "           0.8627, 0.8667, 0.9020, 0.2627],\n",
              "          [0.1882, 0.7961, 0.7176, 0.7608, 0.8353, 0.7725, 0.7255, 0.7451,\n",
              "           0.7608, 0.7529, 0.7922, 0.8392, 0.8588, 0.8667, 0.8627, 0.9255,\n",
              "           0.8824, 0.8471, 0.7804, 0.8078, 0.7294, 0.7098, 0.6941, 0.6745,\n",
              "           0.7098, 0.8039, 0.8078, 0.4510],\n",
              "          [0.0000, 0.4784, 0.8588, 0.7569, 0.7020, 0.6706, 0.7176, 0.7686,\n",
              "           0.8000, 0.8235, 0.8353, 0.8118, 0.8275, 0.8235, 0.7843, 0.7686,\n",
              "           0.7608, 0.7490, 0.7647, 0.7490, 0.7765, 0.7529, 0.6902, 0.6118,\n",
              "           0.6549, 0.6941, 0.8235, 0.3608],\n",
              "          [0.0000, 0.0000, 0.2902, 0.7412, 0.8314, 0.7490, 0.6863, 0.6745,\n",
              "           0.6863, 0.7098, 0.7255, 0.7373, 0.7412, 0.7373, 0.7569, 0.7765,\n",
              "           0.8000, 0.8196, 0.8235, 0.8235, 0.8275, 0.7373, 0.7373, 0.7608,\n",
              "           0.7529, 0.8471, 0.6667, 0.0000],\n",
              "          [0.0078, 0.0000, 0.0000, 0.0000, 0.2588, 0.7843, 0.8706, 0.9294,\n",
              "           0.9373, 0.9490, 0.9647, 0.9529, 0.9569, 0.8667, 0.8627, 0.7569,\n",
              "           0.7490, 0.7020, 0.7137, 0.7137, 0.7098, 0.6902, 0.6510, 0.6588,\n",
              "           0.3882, 0.2275, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1569,\n",
              "           0.2392, 0.1725, 0.2824, 0.1608, 0.1373, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
              " tensor(9, dtype=torch.uint8))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataloader\n",
        "The dataloader helps with the retrival of the data; it shuffles, divides in batches etc. all of the data.\n",
        "\n",
        "During training the dataloader, \"loads\" the data to the model as needed."
      ],
      "metadata": {
        "id": "M3Tj6PO0uQnT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(data_training, batch_size=32, shuffle=True)\n",
        "eval_dataloader = DataLoader(data_eval, batch_size=32, shuffle=True)\n",
        "test_dataloader = DataLoader(data_testing, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "EImVWUh5uWzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building the model.\n",
        "\n",
        "For the model it is necessary to create another class that inherits the attributes and methods of nn.Module; all of this with the purpose of having flexibility when building the model.\n",
        "\n",
        "Another aspect that is important in the model class definition is the \"forward\" function, which allows the model to perform the computations through the model."
      ],
      "metadata": {
        "id": "MJa8bDsMXdWY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FashionModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.convolution1 = nn.Conv2d(1, 16, kernel_size=(3,3), stride=1, padding=\"same\")\n",
        "        self.activation1 = nn.ReLU()\n",
        "        self.batchn1  = nn.BatchNorm2d(16)\n",
        "\n",
        "        self.convolution2 = nn.Conv2d(16, 32, kernel_size=(3,3), stride=1, padding=\"same\")\n",
        "        self.activation2 = nn.ReLU()\n",
        "        self.maxpool2 = nn.MaxPool2d(kernel_size=(2, 2))\n",
        "        self.batchn2  = nn.BatchNorm2d(32)\n",
        "\n",
        "        self.convolution3 = nn.Conv2d(32, 32, kernel_size=(3,3), stride=1, padding=\"same\")\n",
        "        self.activation3 = nn.ReLU()\n",
        "        self.maxpool3 = nn.MaxPool2d(kernel_size=(2, 2))\n",
        "        self.batchn3  = nn.BatchNorm2d(32)\n",
        "\n",
        "        self.flatten4 = nn.Flatten()\n",
        "        self.linear4 = nn.Linear(1568,256)\n",
        "        self.activation4 = nn.ReLU()\n",
        "        self.dropout4 = nn.Dropout(0.5)\n",
        "\n",
        "        self.linearfinal = nn.Linear(256, 10)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.activation1(self.convolution1(x))\n",
        "        x = self.activation2(self.convolution2(x))\n",
        "        x = self.maxpool2(x)\n",
        "        x = self.activation3(self.convolution3(x))\n",
        "        x = self.maxpool3(x)\n",
        "        x = self.flatten4(x)\n",
        "        x = self.activation4(self.linear4(x))\n",
        "        x = self.dropout4(x)\n",
        "\n",
        "        x = self.linearfinal(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "8ERccQ27Xfqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training\n",
        "\n",
        "To train the model a \"for\" loop is applied according to the desired number of epochs that the model will be trained.\n",
        "\n",
        "After some epochs the model will stop improving; it is important to keep in mind the simplicity of the exercise presented here. There are more ways to improve the accuracy and performance of the model. For example, more transformations, normalization of the tensors, a different setting of the model etc. Despite of this, the model still reaches an accuracy of over 90% with the validation dataset."
      ],
      "metadata": {
        "id": "LJ1RAINlf90F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = FashionModel()\n",
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "epochs = 15\n",
        "for epoch in range(1, epochs+1):\n",
        "    for input, label in train_dataloader:\n",
        "        # forward, backward, and then weight update\n",
        "        y_pred = model(input)\n",
        "        loss1 = loss(y_pred, label)\n",
        "        optimizer.zero_grad()\n",
        "        loss1.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    accuracy = 0\n",
        "    count = 0\n",
        "    for inputs, labels in eval_dataloader:\n",
        "        y_pred = model(inputs)\n",
        "        accuracy += (torch.argmax(y_pred, 1) == labels).float().sum()\n",
        "        count += len(labels)\n",
        "    accuracy /= count\n",
        "    print(\"Epoch's %d accuracy: %.2f%%\" % (epoch, accuracy*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvfxTUVAf_tl",
        "outputId": "c0b6ff07-b65c-47d4-8248-2c3ef6945dbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch's 1 accuracy: 86.60%\n",
            "Epoch's 2 accuracy: 88.23%\n",
            "Epoch's 3 accuracy: 89.17%\n",
            "Epoch's 4 accuracy: 89.93%\n",
            "Epoch's 5 accuracy: 89.93%\n",
            "Epoch's 6 accuracy: 90.67%\n",
            "Epoch's 7 accuracy: 90.77%\n",
            "Epoch's 8 accuracy: 90.97%\n",
            "Epoch's 9 accuracy: 91.60%\n",
            "Epoch's 10 accuracy: 90.50%\n",
            "Epoch's 11 accuracy: 91.37%\n",
            "Epoch's 12 accuracy: 91.50%\n",
            "Epoch's 13 accuracy: 90.30%\n",
            "Epoch's 14 accuracy: 91.20%\n",
            "Epoch's 15 accuracy: 90.93%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For each epoch of training the loop outputs the accuracy of the validation dataset as a reference of how the model is training and improving.\n",
        "\n",
        "It is important to consider that this \"accuracy\" is only a reference of the training performance and the use of the validation set. It is also necessary to make the model deal with unseen data and discover if the model is overfitted or has learned features, patterns or functions that make the right inference and provide high accuracy."
      ],
      "metadata": {
        "id": "a9b-HUhEapNO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluating the model.\n",
        "\n",
        "In Pytorch once the model has finished the training phase, it is ready to be evaluated. For this, a function call is made to change the model  from 'training' to 'inference' (evaluating) mode.\n",
        "\n",
        "This means that certain features are not functioning as they would while training; basically the model stops learning and just makes inferences without affecting the learned parameters."
      ],
      "metadata": {
        "id": "dQELN7eUcLQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "id": "J6Q2XfqZdKqo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfb4a5d9-a598-4e61-ea18-492fca615b11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FashionModel(\n",
              "  (convolution1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (activation1): ReLU()\n",
              "  (batchn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (convolution2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (activation2): ReLU()\n",
              "  (maxpool2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "  (batchn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (convolution3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (activation3): ReLU()\n",
              "  (maxpool3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "  (batchn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (flatten4): Flatten(start_dim=1, end_dim=-1)\n",
              "  (linear4): Linear(in_features=1568, out_features=256, bias=True)\n",
              "  (activation4): ReLU()\n",
              "  (dropout4): Dropout(p=0.5, inplace=False)\n",
              "  (linearfinal): Linear(in_features=256, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next code block outputs the shape of a random sample that will be used to infere a result. This is to have a reference of what kind of shape is necessary to work with the model and what to expect as an output."
      ],
      "metadata": {
        "id": "L-RwiN7xCOY-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample= np.random.randint(0, 7000)\n",
        "print(sample)\n",
        "\n",
        "y= data_testing[sample][1]\n",
        "print(y)\n",
        "print(data_testing[sample][0].size())\n",
        "x = data_testing[sample][0]\n",
        "x=torch.unsqueeze(x, 0)\n",
        "print(x.size())\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(x)\n",
        "    max, max_indices = torch.max(outputs, dim=1)\n",
        "print(max_indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tpT9GmLk8wg",
        "outputId": "717e2df9-d040-4116-a441-0b8e55947469"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2500\n",
            "tensor(7, dtype=torch.uint8)\n",
            "torch.Size([1, 28, 28])\n",
            "torch.Size([1, 1, 28, 28])\n",
            "tensor([7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### A small test for 10 samples.\n",
        "\n",
        "Time to test the model with some random samples. The code will output the model's prediction, the actual label and the image of the sample."
      ],
      "metadata": {
        "id": "QiRazRLvDgGE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "imgs=x_test[3000:]\n",
        "\n",
        "with torch.no_grad():\n",
        "    for test in range(1,11):\n",
        "        sample= np.random.randint(0, 7000)\n",
        "        y= data_testing[sample][1]\n",
        "\n",
        "        x = data_testing[sample][0]\n",
        "        x=torch.unsqueeze(x, 0)\n",
        "\n",
        "\n",
        "        outputs = model(x)\n",
        "        max, max_indices = torch.max(outputs, dim=1)\n",
        "        predict = mnist_classes[max_indices.item()]\n",
        "        label = mnist_classes[y.item()]\n",
        "        print(f\"Prediction by the model:{predict} \\nActual label:{label}\" )\n",
        "\n",
        "        #plotting the image\n",
        "        fig = plt.figure(figsize=(1.5, 1.5))\n",
        "\n",
        "\n",
        "        plt.imshow(imgs[sample],cmap=\"Greys\")\n",
        "        plt.grid(False)\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "        print(\"================================\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "22ac2f18-b66c-43f9-8c03-f23d6ca6a7b7",
        "id": "0C5GbFB5iIax"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction by the model:Sneaker \n",
            "Actual label:Sneaker\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 150x150 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\n",
            "Prediction by the model:Sandal \n",
            "Actual label:Sandal\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 150x150 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\n",
            "Prediction by the model:Shirt \n",
            "Actual label:Shirt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 150x150 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\n",
            "Prediction by the model:Pullover \n",
            "Actual label:Pullover\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 150x150 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\n",
            "Prediction by the model:Pullover \n",
            "Actual label:Pullover\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 150x150 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIcAAACHCAYAAAA850oKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAHXElEQVR4nO2dyWoVWxSGK/a9RonGXrBBVLDBmcM4VZ9BUN9EwfcQnPgEPoKoOFAEEXtjsI19b+7U9dVep5JwTlXuvd83+z1J7arwu/c6a629a2hqamqqEikwr+sbkLmL5pAUzSEpmkNSNIekaA5J0RySojkkRXNIyoKub6CfvHz5svZvJ0+eDPrbt29B7927t+c137x5E/SNGzeCvnjxYu13zpw5E/TQ0FDPMeYqzhySojkkZWguF94+fPgQ9N27d4P+/Plz0AsW1FfJ5cuXBz0+Ph70x48fg/7582fQDx48CHpsbCzo4eHh2piTk5M973Pr1q1B79y5M+glS5bUrtkFzhySojkkRXNIypyKOfg1kfEB1+I1a9YEXYo5fvz4EfS8efH/w6NHj4J+/vx50PyqOzIy0vN6pfv49etX0Ixz/vz5E/ShQ4eC5nO2hTOHpGgOSdEcktJpzMF8wM2bN4Pm+s74gTHIly9fGsdcsWJFz2sQ5j2+f//eOMbv3797fj5//vyg+VxM8R87dqxxzEHgzCEpmkNSNIekaA5J6bSf486dO0E/fPgw6B07dgTNZBKTRwsXLqyNweCPQevbt2+DZqGuKV7nPZVgUqx0n3/z/v37nnr16tWNY/YDZw5J0RySojkkpdOYg8kixgPv3r0LetGiRUGzGYifV1VVLV68OGiu92y8+fr1a89rUn/69Kk2Jv+NSS4+N4t3Tc1CxhzSOZpDUjSHpLQaczSt51yb2eyzf//+oLlWr1y5sjYmcwwsajHPwbwG4wfmTVgcrKp6cY9j8JrMY3CMUhNTGzhzSIrmkBTNISmd5jm4trJOcf369aAPHDgQNDcUMR9QVfX1nrCWQs1cCscoNfZs3rw5aD7n0qVLg+Zzjo6OBs3Ya/369bUxB4Ezh6RoDknRHJLSaszB/gt+f1+7dm3Q9+7dC5p5DfZ/lGorhLUVxgyMMZiDYK2Gz1RV9Y1SjFMY1xDGHBMTEz1/flA4c0iK5pAUzSEprcYcrGtwg9DRo0eDvnz5ctCsSfBgFfZmVFU9p7Bp06ageeYX13vGJPz9UjzAGhE3RjH30nQIzXRiqUHgzCEpmkNSNIektBpzcG3lISbbtm3r+fmVK1eC5vpf2hTNes1MeykYJzEPUtq3whiDYzx58iRoxjU8t5Q9o6UxB9Hz4cwhKZpDUjSHpGgOSWk1IG068YZFMTYM379/P+jpBKQscjHptW7duqDZYMxiYGkTE+F98L6pGYgzKGay0IBUOkdzSIrmkJROG4yZLOJayuTPpUuXgj579mzjGIwhGA8wpmCijr/PDUulF+3wObgZi3ELN4yzoYif8+9WVYN504Izh6RoDknRHJLSaszB7+tsGGaBim8LOH78eNBc70sHsbGxpum0YOZieE023pRyDmwwYq7l1KlTQV+4cCFo5izYxNyUL+oXzhySojkkRXNISqeHt7B28urVq6C5cfr06dNBs8G4dHgL4xLGDMuWLQt61apVQbPO8fTp06BLb2piHLNhw4ag9+zZEzRjEr48mX+XtnDmkBTNISmaQ1I6ra0Qbpzm+n/w4MGgHz9+HHTpLUpNh+nzYNxS3eJvmg6gq6p6LqXpIHzWdxjnMK9hnkM6R3NIiuaQlFZjDq7vjCmePXsW9L59+4JmfwfXe67104G/w5iEMQtjDsYHVVXvreDmLMY1PACOP89azWyeczY4c0iK5pAUzSEpc+rAOK7frINwA/J0YE6g6dB59ozy52fzAm/GCIy9du/eHTTrN9u3b5/xmP3AmUNSNIekaA5J0RyS0mnhjQmmppP7bt++HTSTR6UCV1Mhrakwx2ae6WxYZtDKa3LTEgtv3OzN5yoV+waBM4ekaA5J0RyS0mrMwbWY6z0TTlu2bAn62rVrQW/cuDHo0lrMOKapaMUYo6kQVyq8Nb1R8sWLF0GzUMe3Lhw5cqTnPQwKZw5J0RySojkkpdM8B9d/bv7hQSmE+YHSW5OYI+D6T831vynvUYK5FW4If/36dc8xyUzf9NQvnDkkRXNIiuaQlE6bffh9nRuhqbmWsxG3BNdrNuuyzjHTukVT7aZ0TT4Xa0RNDUrTGbMfOHNIiuaQFM0hKa3GHMwRcO0sbYT+m6tXrwY9NjYWdOktily/m9brprwG8yalHAXjmvHx8aDZE3Lu3LmgecgN79mN1NI5mkNSNIekdJrn4Pd3rrXk/PnzQTNGYc6iquobiEjTQSmlfo0mGJdwQzjfnM1aCTeY83rmOaRzNIekaA5J6TTPwbW0qU/h8OHDfb+nuchMczGDwplDUjSHpGgOSdEcktJqQMoCFBNMTSf9Em6SKr2p8d/I8PBw0HyD9a5du1q5D2cOSdEckqI5JKXVmIPJnVu3bgV94sSJGV3vvxJjEB5aMzExEbQxh3SO5pAUzSEprcYco6OjQU9OTgY9MjLS4t3MXXiiMTdFuZFaOkdzSIrmkJShqdm8BkD+FzhzSIrmkBTNISmaQ1I0h6RoDknRHJKiOSRFc0jKPwUh5WTgGBZLAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\n",
            "Prediction by the model:Sneaker \n",
            "Actual label:Sneaker\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 150x150 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\n",
            "Prediction by the model:Sneaker \n",
            "Actual label:Sneaker\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 150x150 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\n",
            "Prediction by the model:Trouser \n",
            "Actual label:Trouser\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 150x150 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIcAAACHCAYAAAA850oKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAFKUlEQVR4nO3duU4dWRSF4cNgM09msMQobEAiIHJARkpCwjsg8RJkxLwLCS9BQEpCAAgkZJlBgJiHTjpgr6p1L6gt2af6/7INZW7ZWj7ePkNVw+vr62sCSjT+6RvA34twwCIcsAgHLMIBi3DAIhywCAcswgGr+U/fwO+0vr5e+Nr+/n6oOzs7Q/34+Bjq+/v7UOsEcnNz/CMbHx8vfOba2lrde80BIwcswgGrIeeFt9vb21C3t7cXrvn27Vuo9bfb2Fj778fLy0uoW1tbQ727u1v4NQ8PD6H+9OlTzc/4WzFywCIcsAgHrKz/K7u9vR3qycnJwjWDg4Ohvrq6CvXnz59r1tpz6Pc7OjoKn7mzsxPq+fn5wjU5YOSARThgEQ5YWfccJycnoT48PCxc09/fH2qd57i7uwt1Q0NDzc/U72tPUnZfuWLkgEU4YBEOWIQDVtYN6cHBQah1USyl4mKc7teot/Cm+z30et3fkVJKx8fHNX9mLhg5YBEOWIQDVtY9x69fv0JdtqmmqampZn1xcRFq7TH6+vpC/fz8HOqWlpbCZ56dnZXfcGYYOWARDliEA1bWPYf++1+2V1o35+hmH6U9xOXlZai7u7tDXTZPon1Lrhg5YBEOWIQDVtY9h66b6GGilIprH+fn56He2NgI9dPTU6hXV1dDPTU1Feqy/kLnUnLFyAGLcMAiHLCy7jl6e3tDrf1CSsV5Dd0QfHR0FGpdS1E3NzehLutzdC4kV4wcsAgHLMIBK+ueY3Z2NtR6aLqMHkrSeYqyfahv6VqKHopKKaWRkZG695EDRg5YhAMW4YCVdc8xNzcX6rI1Dd3zoXMh2oOUPXTuLZ0nmZiYqHtfuWLkgEU4YBEOWIQDVtYN6djYWKjLJrC0AR0aGgq1NrEDAwOh1k3L9Z4umFJK379/N3ecF0YOWIQDFuGAlXXPofQAUkrlB53f0pfz6Mt19GmEulBX9uTAXN+SoBg5YBEOWIQDVqV6juXl5cLXtra2Qq3zEl1dXaH++vVrqHVzz/X1dagXFhY+fJ+5YOSARThgEQ5Yleo5VlZWCl/b3NwMta6l9PT0hFrXZ3QzkB5qWlpa+uhtZoORAxbhgEU4YFWq59BDTikV5zH0EJKug2iPobWu1SwuLn74PnPByAGLcMAiHLAq1XOU7aPQQ0o6T6E9hD6MRfdv6NpMvYPXOWPkgEU4YBEOWJXqOcoepKL7L/QcS0dHR6j14LXW2oOUvZG6Khg5YBEOWIQDFuGAVamG9D1vSNJJL2049YnHer1uFqIhxf8S4YBFOGBVqucoOzStPYL2JT9//gy1vjVBDzXpm5/K3g5ZFdX9neE/IxywCAesSvUcuoiWUkpfvnwJ9fHxcajb2tpCrT2HzmPo9frzq4SRAxbhgEU4YFWq5ygzPDwc6r29vVDroSd925NuONaH3JY9pLYqGDlgEQ5YhANW5XsOfXj+7e1tqEdHR0Oth5R007L+vCpj5IBFOGARDlhZ9xz6ohx90EpKKU1PT4da94zqg+91f4ZePzU19VvuKweMHLAIByzCASvrnuM96u23+OgeUF1bqTJGDliEAxbhgEU4YFW+IdW3Iqh6DakeitLNQFXGyAGLcMAiHLCy7jnes8BV7wnFp6enodYe5P7+vubPqzJGDliEAxbhgJV1z/GeTTQ/fvwItb5BemBgINSdnZ2h1jcxzczMfOQWs8bIAYtwwCIcsBpedbIA+BcjByzCAYtwwCIcsAgHLMIBi3DAIhywCAesfwDpGyuzNJmS0QAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\n",
            "Prediction by the model:Trouser \n",
            "Actual label:Trouser\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 150x150 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIcAAACHCAYAAAA850oKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAFtklEQVR4nO3dy05UTRTF8cIr3gFFFDQYQOMlIRomJoyML+Az+Bq+gjNegyeQmTOdaGKMI3GAgBINyk0QhG/qXlWrjyZfYtfJ/zfb2N2nTZbFtk5VnZ6Dg4ODBBQc+tdfAN2LcMAiHLAIByzCAYtwwCIcsAgHLMIB68i//gL/p8ePH2c/e/HiRainpqZCrRPEJ0+eDPX+/n6oNzc3Q/3hw4fsmtPT06F++vSp+cbdjZEDFuGA1apfK7Ozs9nPRkdHQ728vBzqX79+hXp+fj7UFy5c6Ph5p0+fzq65uLjY/GUrwMgBi3DAIhywqu45FhYWQr2zs5O9RnuEI0fiX3lrayvUV65cCfX4+HioP3/+HOrjx49n19zY2Oh4Df3vcrdi5IBFOGARDlhV9xwvX74MdWmttM5DfP36NdSXLl0K9erqasfP1NeXrvnq1atQf/r0KdRjY2PZe7oRIwcswgGLcMAiHLCqbkjfvn0b6sHBwcb36PoLrXVS6927d6HWSTRdu5FSStevXw/19+/fG79XN2LkgEU4YBEOWFX3HO/fvw/1uXPnstcMDAyE+tGjR6F+9uxZqI8dOxbqixcvhvrHjx+hXlpayq45PDwc6o8fP4b63r172Xu6ESMHLMIBi3DAqrrn6OnpCfXk5GT2mqGhoVCvrKyEWvuDubm5ju9/8OBBqC9fvpxdUxcE/fz5M3tNDRg5YBEOWIQDVtU9hy606e/vz15z9uzZUG9vb4f66NGjoX748GGodaGOzqVcu3Ytu+aZM2dCTc+B1iEcsAgHrKp7jjt37oRa13eklNL58+dDrRuO+vr6Qq33UnRjtc6LlPoJ7X10UXItGDlgEQ5YhANW1T3H/fv3Q/38+fPsNbo+Qzcx6+brJ0+ehHpmZibUOk9S2qCk6zd0c3YtGDlgEQ5YhANW1T3HxMREqEuHt+g+E72XonTN6e7ubqh1D8qhQ/m/Lz27VO+11IKRAxbhgEU4YBEOWFU3pE0bjlJKaW9vL9R6YrHeSFO6iFkbWm14U8oXIWmTWwtGDliEAxbhgFV1z/EnE1y6iUn19vZ2/PNbt26FWie99MZe6XuUXlMDRg5YhAMW4YBVdc+hSk9N0icW6O//tbW1jp+pi4V13qP0BAS9ps6tHD58uOM1uwUjByzCAYtwwGpVz6H3WlLKFwCdOnUq1NoPNNF5jtLcih50W0uPoRg5YBEOWIQDVqt6jtI9jC9fvoRanzDdROdBtIfRBcgppXTz5s2/uka3YuSARThgEQ5Yreo5dA4jpZTW19dDrRuhm+6t6L0TXR9aWi+yubnZ8TNrwcgBi3DAIhywWtVzjIyMZD97/fp1qLUfaNpTcuPGjVBrz1J6GM/f3q/pVowcsAgHLMIBi3DAalVDWlpgrDfKvn37FurSyTy/05N8dNLsxIkT2Xtu377d8TNrwcgBi3DAIhywWtVz6ARVSvnhLfqapo3W+sSDxcXFUOuNuJTy0wRrxcgBi3DAIhywWtVzjI6OZj/TeQp9clNpgdDv9HAX7TlKN+5qPbFYMXLAIhywCAesVvUcpY3UepCKPh1Sn1itVldXQ60LefTzU8o3UteKkQMW4YBFOGC1qucozS/oeg59grQeAKd0c7beqyk9HarWg/AVIwcswgGLcMBqVc+hB8qmlK+t0HkOXa+hdI2oznOUDm8pHVxbI0YOWIQDFuGA1aqeo3QYrPYEuoZUD3dRTftaSpumm+ZOasHIAYtwwCIcsAgHrFY1pKWFO/oESW1AmxrOpkmyUvN59erVju+pBSMHLMIBi3DAalXPUdrUrIet6Cal0uErvxseHg613rgrLTAuPb2pRowcsAgHLMIBq1U9R2mRzd27d0P95s2bUA8NDXX8zMnJyVD39fWFemJi4o++R40YOWARDliEA1bPQWlyAEiMHOiAcMAiHLAIByzCAYtwwCIcsAgHLMIB6z8FsnLbsoWY8AAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\n",
            "Prediction by the model:Trouser \n",
            "Actual label:Trouser\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 150x150 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Inferring 5000 images to test the model's accuracy.\n",
        "\n",
        "It's necessary to confirm the model's not overfitted and check if it has generalized the parameters well enough to have a constant and useful accuracy. Testing the model with 5000 samples will be a good way to see this."
      ],
      "metadata": {
        "id": "RAwM1k8yEHL6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correct_total=0\n",
        "with torch.no_grad():\n",
        "\n",
        "    for test in range(0,5000):\n",
        "        #sample= np.random.randint(0, 7000)\n",
        "        sample= test\n",
        "        y= data_testing[sample][1]\n",
        "\n",
        "        x = data_testing[sample][0]\n",
        "        x=torch.unsqueeze(x, 0)\n",
        "\n",
        "\n",
        "        outputs = model(x)\n",
        "        max, max_indices = torch.max(outputs, dim=1)\n",
        "        predict = mnist_classes[max_indices.item()]\n",
        "        label = mnist_classes[y.item()]\n",
        "        if predict == label:\n",
        "            correct_total += 1\n",
        "\n",
        "\n",
        "\n",
        "test_result = (correct_total/5000) * 100\n",
        "\n",
        "print(f\"Percentege of correct predictions by the model:{test_result}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtlDPhKAkMnY",
        "outputId": "9fadc652-4cd6-4c18-85d7-ff7676dd6945"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentege of correct predictions by the model:91.8%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The accuracy of the model is over 91%, 9 out of 10 samples are correctly inferred. This shows that the model is not overfitted and the parameters work to extract the features and functions that are required to make the inferences.\n",
        "\n",
        "Pytorch and Deep learning in general are powerful tools. Despite the simplicty in the exercise, the results are a glimpse of what can be achieved, improved and created."
      ],
      "metadata": {
        "id": "Yi6MfrGdGUrT"
      }
    }
  ]
}