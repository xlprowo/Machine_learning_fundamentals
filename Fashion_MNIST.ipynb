{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c324daad",
      "metadata": {
        "id": "c324daad"
      },
      "source": [
        "#  Basic neural network in Keras. Fashion MNIST\n",
        "\n",
        "#### Objective:\n",
        "\n",
        "Model and train a neural network using Keras in order to classify the elements of a dataset correctly."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "241d5cd5",
      "metadata": {
        "id": "241d5cd5"
      },
      "source": [
        "#### Install dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "459388cb",
      "metadata": {
        "id": "459388cb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e7a2b4b",
      "metadata": {
        "id": "9e7a2b4b"
      },
      "source": [
        "#### Load the dataset from keras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c961b101",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c961b101",
        "outputId": "48ac8f2a-b4f3-405c-96c0-4796b2d3352a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test)= keras.datasets.fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ccb5449",
      "metadata": {
        "id": "2ccb5449"
      },
      "source": [
        "#### Shape of the train samples and the train labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5f8a7ab",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5f8a7ab",
        "outputId": "01c4e0b1-19bf-4835-9476-6cc1f3ab5abe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(10000, 28, 28)\n",
            "(10000,)\n"
          ]
        }
      ],
      "source": [
        "print(np.shape(x_train))\n",
        "print(np.shape(y_train))\n",
        "print(np.shape(x_test))\n",
        "print(np.shape(y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2fb22ce",
      "metadata": {
        "id": "f2fb22ce"
      },
      "source": [
        "#### Category dictionary:\n",
        "\n",
        "A dictionary with the corresponding values of each category."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f06cd74c",
      "metadata": {
        "id": "f06cd74c"
      },
      "outputs": [],
      "source": [
        "mnist_classes= {0:\"T-shirt/top\",\n",
        "                1:\"Trouser\",\n",
        "                2:\"Pullover\",\n",
        "                3:\"Dress\",\n",
        "                4:\"Coat\",\n",
        "                5:\"Sandal\",\n",
        "                6:\"Shirt\",\n",
        "                7:\"Sneaker\",\n",
        "                8:\"Bag\",\n",
        "                9:\"Ankle boot\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31799bdc",
      "metadata": {
        "id": "31799bdc"
      },
      "source": [
        "#### Plotting a sample:\n",
        "\n",
        "A sample of the training set is plotted as a reference of the images. The sample is chosen randomly and it shows its corresponding category."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09316100",
      "metadata": {
        "id": "09316100"
      },
      "outputs": [],
      "source": [
        "sample = np.random.randint(0, x_train.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd6dad73",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "dd6dad73",
        "outputId": "324dcba1-a704-4691-e77c-b8c6b79fddc5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 200x200 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.figure(figsize = (2,2))\n",
        "mnist_img = x_train[sample]\n",
        "plt.imshow(mnist_img,cmap=\"Greys\")\n",
        "ax = plt.gca()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c6ad979",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c6ad979",
        "outputId": "eb168257-57d2-4be7-9cdb-6c4c9d96d269"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dress\n"
          ]
        }
      ],
      "source": [
        "print(mnist_classes[y_train[sample]])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ebe3e44",
      "metadata": {
        "id": "2ebe3e44"
      },
      "source": [
        "#### Data preprocessing.\n",
        "It is necesseray to preprocess the data in order to feed the neural network with the appropriate format.\n",
        "\n",
        "Since the model arquitecture is a simple one consisting of\n",
        "a couple of sequential dense layers, the data needs to be reshaped to fit the input shape; in this case instead of a two dimensional format, reshaping the images to a flatten shape of one dimension (28*28=784) will allow the model to process the data with the neurons of the network.\n",
        "\n",
        "The format of the labels is also changed to a one-hot encoding that allows to use the 'sparse_categorical_crossentropy' loss function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "350eaf01",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "350eaf01",
        "outputId": "2593d444-3d19-42f8-cade-6c21a6181c6b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 1., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "n_classes=10\n",
        "keras.utils.to_categorical(y_train, n_classes)\n",
        "keras.utils.to_categorical(y_test, n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71f14433",
      "metadata": {
        "id": "71f14433"
      },
      "outputs": [],
      "source": [
        "x_train = x_train.reshape(60000, 784).astype('float32')\n",
        "x_test = x_test.reshape(10000, 784).astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39996130",
      "metadata": {
        "id": "39996130"
      },
      "source": [
        "#### Neural network model\n",
        "\n",
        "A sequential model with two hidden layers. The purpose of this exercise is to use a simple neural network to classify the images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6f109ed",
      "metadata": {
        "id": "e6f109ed"
      },
      "outputs": [],
      "source": [
        "model = keras.models.Sequential()\n",
        "\n",
        "model.add(keras.layers.Dense(16, activation='relu', input_shape=(784,)))\n",
        "\n",
        "model.add(keras.layers.Dense(32, activation='relu'))\n",
        "\n",
        "model.add(keras.layers.Dense(10, activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Summary of the model"
      ],
      "metadata": {
        "id": "CFz9CeM2kobF"
      },
      "id": "CFz9CeM2kobF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d66705b5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d66705b5",
        "outputId": "20a0aa74-82c6-43d9-c9ec-600fbf1b02b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 16)                12560     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32)                544       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13434 (52.48 KB)\n",
            "Trainable params: 13434 (52.48 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output of the model's summary shows that it is a very simple model with only 13434 parameters to train. This is a very small quatity compared to the millions other arquitectures have; of course those are more accurate and trained for more complex tasks or difficult problems. However the simple arquitecture of the model presented here really shows the capabilities of deep learning."
      ],
      "metadata": {
        "id": "uiqFT3AllccN"
      },
      "id": "uiqFT3AllccN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Compile and train the model.\n",
        "\n",
        "To compile the model the sparse categorical crossentropy, adam and accuracy where used as loss function, as optimizer and metrics respectively.\n",
        "\n"
      ],
      "metadata": {
        "id": "L1rhMgNYmU7L"
      },
      "id": "L1rhMgNYmU7L"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f91a1650",
      "metadata": {
        "id": "f91a1650"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To train the model 25 epochs are more than enough for the neural network to capture the necessary features."
      ],
      "metadata": {
        "id": "BNgWQRiwteNz"
      },
      "id": "BNgWQRiwteNz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9384776",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9384776",
        "outputId": "fc545dbb-c41d-44f6-f741-fb31c2ca42f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "469/469 [==============================] - 7s 10ms/step - loss: 0.7337 - accuracy: 0.7430 - val_loss: 0.5171 - val_accuracy: 0.8179\n",
            "Epoch 2/25\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.4574 - accuracy: 0.8378 - val_loss: 0.4582 - val_accuracy: 0.8364\n",
            "Epoch 3/25\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.4143 - accuracy: 0.8535 - val_loss: 0.4389 - val_accuracy: 0.8410\n",
            "Epoch 4/25\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.3917 - accuracy: 0.8599 - val_loss: 0.4183 - val_accuracy: 0.8503\n",
            "Epoch 5/25\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3761 - accuracy: 0.8660 - val_loss: 0.4032 - val_accuracy: 0.8555\n",
            "Epoch 6/25\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3662 - accuracy: 0.8684 - val_loss: 0.4026 - val_accuracy: 0.8541\n",
            "Epoch 7/25\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.3580 - accuracy: 0.8714 - val_loss: 0.3987 - val_accuracy: 0.8588\n",
            "Epoch 8/25\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3493 - accuracy: 0.8737 - val_loss: 0.3941 - val_accuracy: 0.8591\n",
            "Epoch 9/25\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3437 - accuracy: 0.8766 - val_loss: 0.3887 - val_accuracy: 0.8595\n",
            "Epoch 10/25\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3361 - accuracy: 0.8781 - val_loss: 0.4161 - val_accuracy: 0.8536\n",
            "Epoch 11/25\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3303 - accuracy: 0.8798 - val_loss: 0.3860 - val_accuracy: 0.8607\n",
            "Epoch 12/25\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3277 - accuracy: 0.8805 - val_loss: 0.3841 - val_accuracy: 0.8654\n",
            "Epoch 13/25\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3229 - accuracy: 0.8824 - val_loss: 0.3735 - val_accuracy: 0.8649\n",
            "Epoch 14/25\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3177 - accuracy: 0.8838 - val_loss: 0.3804 - val_accuracy: 0.8641\n",
            "Epoch 15/25\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3149 - accuracy: 0.8852 - val_loss: 0.3835 - val_accuracy: 0.8606\n",
            "Epoch 16/25\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3091 - accuracy: 0.8870 - val_loss: 0.3890 - val_accuracy: 0.8627\n",
            "Epoch 17/25\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3100 - accuracy: 0.8863 - val_loss: 0.3811 - val_accuracy: 0.8649\n",
            "Epoch 18/25\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3053 - accuracy: 0.8882 - val_loss: 0.3832 - val_accuracy: 0.8643\n",
            "Epoch 19/25\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3018 - accuracy: 0.8885 - val_loss: 0.3795 - val_accuracy: 0.8655\n",
            "Epoch 20/25\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2997 - accuracy: 0.8885 - val_loss: 0.3744 - val_accuracy: 0.8696\n",
            "Epoch 21/25\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.2977 - accuracy: 0.8904 - val_loss: 0.3837 - val_accuracy: 0.8651\n",
            "Epoch 22/25\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2969 - accuracy: 0.8900 - val_loss: 0.3761 - val_accuracy: 0.8650\n",
            "Epoch 23/25\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2930 - accuracy: 0.8919 - val_loss: 0.3702 - val_accuracy: 0.8678\n",
            "Epoch 24/25\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2903 - accuracy: 0.8927 - val_loss: 0.3773 - val_accuracy: 0.8691\n",
            "Epoch 25/25\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2882 - accuracy: 0.8930 - val_loss: 0.3780 - val_accuracy: 0.8659\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x79cf88df1db0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "model.fit(x_train, y_train, batch_size=128, epochs=25,\n",
        "          verbose=1, validation_data=(x_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model's evaluation.\n",
        "\n",
        "The model's evalution outputs an accuracy of 86%. The result might not look impressive at first glance but despite it used few parameters and the images are not very clear the model was still able to achieve a 86% of accuracy."
      ],
      "metadata": {
        "id": "ohusFS8Xm6UE"
      },
      "id": "ohusFS8Xm6UE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc046120",
      "metadata": {
        "id": "cc046120",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6877730-75f2-4aa0-c1f3-3fa3e1b805c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3780 - accuracy: 0.8659\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.377964586019516, 0.8658999800682068]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "model.evaluate(x=x_test, y=y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Predicting a random image category.\n",
        "\n",
        "It's time to use the trained model and see if it can predict a random image."
      ],
      "metadata": {
        "id": "fYTffOcD0Zpt"
      },
      "id": "fYTffOcD0Zpt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c2f0c5a",
      "metadata": {
        "id": "1c2f0c5a"
      },
      "outputs": [],
      "source": [
        "sample_test = np.random.randint(0, x_test.shape[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcad1420",
      "metadata": {
        "id": "fcad1420",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7e31166-bd81-4174-e328-cc461672a27b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784,)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "np.shape(x_test[sample_test])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f49604a",
      "metadata": {
        "id": "9f49604a"
      },
      "outputs": [],
      "source": [
        "x = x_test[sample_test].reshape(1,784)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bde8e4d0",
      "metadata": {
        "scrolled": true,
        "id": "bde8e4d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad8b31a2-6c28-46c7-f982-f0faa88acba0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 137ms/step\n"
          ]
        }
      ],
      "source": [
        "result= model.predict(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The image is predicted and an index of the image is selected to see if it matches the same index of the label."
      ],
      "metadata": {
        "id": "wVBs05suG8Uq"
      },
      "id": "wVBs05suG8Uq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3230b449",
      "metadata": {
        "id": "3230b449"
      },
      "outputs": [],
      "source": [
        "prediction= result.argmax()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The prediction outputs \"T-shirt/top\" and the label of the sample is the exact same which means the prediction is correct. And the end the image is displayed to confirm it is a T-shirt/top"
      ],
      "metadata": {
        "id": "cg14d9KLHSeA"
      },
      "id": "cg14d9KLHSeA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f871922",
      "metadata": {
        "id": "3f871922",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "418e7ab5-a22c-4dab-a94a-32bd362c9f8b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'T-shirt/top'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "mnist_classes[prediction]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20f1171f",
      "metadata": {
        "id": "20f1171f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd115a68-c6e4-404a-95b2-4f1c1e962f6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T-shirt/top\n"
          ]
        }
      ],
      "source": [
        "print(mnist_classes[y_test[sample_test]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7e51b85",
      "metadata": {
        "id": "c7e51b85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "22ae86b6-13c6-4f3a-9a9d-3614232d8fa6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 200x200 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "x_test = x_test.reshape(10000, 28, 28).astype('float32')\n",
        "plt.figure(figsize = (2,2))\n",
        "mnist_img = x_test[sample_test]\n",
        "plt.imshow(mnist_img,cmap=\"Greys\")\n",
        "ax = plt.gca()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}