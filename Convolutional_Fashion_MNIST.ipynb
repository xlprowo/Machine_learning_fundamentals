{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "61756e33",
      "metadata": {
        "id": "61756e33"
      },
      "source": [
        "## Convolutional neural network in keras. Fashion MNIST\n",
        "\n",
        "Objective:\n",
        "Model and train a convolutional neural network using Keras in order to classify the elements of a dataset correctly."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa436b16",
      "metadata": {
        "id": "aa436b16"
      },
      "source": [
        "#### Import libraries.\n",
        "\n",
        "All the necessary libraries are imported in the next code block."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "066dc8ea",
      "metadata": {
        "id": "066dc8ea"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.layers import BatchNormalization\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data is retrived and divided into two, one for training and the other for testing."
      ],
      "metadata": {
        "id": "FvXU0MXSOgz8"
      },
      "id": "FvXU0MXSOgz8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9e53868",
      "metadata": {
        "id": "d9e53868",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11973169-5c1b-470a-88e5-637054825643"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 1us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 2s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test)= keras.datasets.fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Shape of the data.\n",
        "\n",
        "In this exercise the model's input will keep the 2 dimensional format of the images (28x28) instead of a flatten input. The 60000 and 10000 represent the number of samples in the training and test sets respectively."
      ],
      "metadata": {
        "id": "trQbTHRmOtot"
      },
      "id": "trQbTHRmOtot"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aaac2929",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaac2929",
        "outputId": "8fc92598-f367-4497-98f8-ca5494fe5715"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(10000, 28, 28)\n",
            "(10000,)\n"
          ]
        }
      ],
      "source": [
        "print(np.shape(x_train))\n",
        "print(np.shape(y_train))\n",
        "print(np.shape(x_test))\n",
        "print(np.shape(y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The labels of the data consist in ten different numbers that reference cloth items. The following block contains the dictionary of each of the items with their respective number than represents them."
      ],
      "metadata": {
        "id": "abaWBW_3PKFS"
      },
      "id": "abaWBW_3PKFS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca583366",
      "metadata": {
        "id": "ca583366"
      },
      "outputs": [],
      "source": [
        "mnist_classes= {0:\"T-shirt/top\",\n",
        "                1:\"Trouser\",\n",
        "                2:\"Pullover\",\n",
        "                3:\"Dress\",\n",
        "                4:\"Coat\",\n",
        "                5:\"Sandal\",\n",
        "                6:\"Shirt\",\n",
        "                7:\"Sneaker\",\n",
        "                8:\"Bag\",\n",
        "                9:\"Ankle boot\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the next two code blocks a random sample of the training data set is selected and the image displayed."
      ],
      "metadata": {
        "id": "ArJgaLmAP0Om"
      },
      "id": "ArJgaLmAP0Om"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8fb8b6e",
      "metadata": {
        "id": "f8fb8b6e"
      },
      "outputs": [],
      "source": [
        "sample = np.random.randint(0, x_train.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d10e8fbc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "d10e8fbc",
        "outputId": "1eb4e22d-e27e-4e9a-99e6-febc8cfe7d6a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 200x200 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "plt.figure(figsize = (2,2))\n",
        "mnist_img = x_train[sample]\n",
        "plt.imshow(mnist_img,cmap=\"Greys\")\n",
        "ax = plt.gca()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Preprocessing the data.\n",
        "\n",
        "In order for the model to get the most out of the data is important to preprocess it. However, for this exercise only labels will be preprocess(one-hot encoding) and the rest of the data will fed to the model as it is after downloading. The purpose of this is to see if the convolutional model's accuracy improves more than a simple linear model.\n",
        "\n",
        "A couple of the preprocess techniques than could have been applied are: normalization and data augmentation."
      ],
      "metadata": {
        "id": "s9ai75RqP--4"
      },
      "id": "s9ai75RqP--4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d56937a4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d56937a4",
        "outputId": "387b7aea-b904-4448-d60e-df4db22a2f13"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 1., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "n_classes=10\n",
        "keras.utils.to_categorical(y_train, n_classes)\n",
        "keras.utils.to_categorical(y_test, n_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f913e77",
      "metadata": {
        "id": "6f913e77"
      },
      "source": [
        "### Model 2\n",
        "\n",
        "For the model three groups of layers with convolutional layers will be defined and then there will be a flatten layer followed by a dense  and a final dense layer to provide the output's result.\n",
        "\n",
        "In the first group there is a convolutional layer and a normalization layer for the batch. The second group will be a convolution layer, a max-pooling layer and a normalization layer. The third group is the same as the second.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), strides=(1, 1), padding=\"same\", activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(256, kernel_size=(3, 3), strides=(1, 1), padding=\"same\", activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), padding=\"same\", strides=(1, 1), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "vhnxXUGHwrbA"
      },
      "id": "vhnxXUGHwrbA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model's information.\n",
        "\n",
        "The model's information is displayed in the following code block. The model is not very deep, however it still has a total of 2,957,450 trainable parameters. The model could be more complex. However the model presented here is good enough to surpass a fully-dense model."
      ],
      "metadata": {
        "id": "K4VCXVCSu4ZL"
      },
      "id": "K4VCXVCSu4ZL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc0b4b36",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc0b4b36",
        "outputId": "3fdeeb49-8b75-4a65-b30b-fc44dc738f31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 28, 28, 128)       1280      \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 28, 28, 128)       512       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 28, 28, 256)       295168    \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 13, 13, 256)       0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 13, 13, 256)       1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 13, 13, 128)       295040    \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 6, 6, 128)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 6, 6, 128)         512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 4608)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               2359808   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2958474 (11.29 MB)\n",
            "Trainable params: 2957450 (11.28 MB)\n",
            "Non-trainable params: 1024 (4.00 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compile and training.\n",
        "\n",
        "Once the model is defined, it is time to compile and choose the loss function, the optimizer and the metrics that will be used.\n",
        "\n",
        "Again, for this model, things will be simple:\n",
        "\n",
        "The sparse categorical crossentropy function to classify the data which has various labels. The optimizer will be one that is commonly used for its good performance and the accuracy metrics to see how well it predicts a correct label"
      ],
      "metadata": {
        "id": "G9XEW5ptwaYu"
      },
      "id": "G9XEW5ptwaYu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1e1f0ac",
      "metadata": {
        "id": "d1e1f0ac"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5ce9d45",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5ce9d45",
        "outputId": "4abbd22d-ac67-4885-c3b9-61658019370a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "329/329 [==============================] - 29s 44ms/step - loss: 0.5279 - accuracy: 0.8252 - val_loss: 0.3272 - val_accuracy: 0.8809\n",
            "Epoch 2/30\n",
            "329/329 [==============================] - 15s 45ms/step - loss: 0.3126 - accuracy: 0.8883 - val_loss: 0.3713 - val_accuracy: 0.8682\n",
            "Epoch 3/30\n",
            "329/329 [==============================] - 15s 45ms/step - loss: 0.2630 - accuracy: 0.9051 - val_loss: 0.2475 - val_accuracy: 0.9131\n",
            "Epoch 4/30\n",
            "329/329 [==============================] - 14s 43ms/step - loss: 0.2284 - accuracy: 0.9160 - val_loss: 0.2369 - val_accuracy: 0.9189\n",
            "Epoch 5/30\n",
            "329/329 [==============================] - 15s 46ms/step - loss: 0.2058 - accuracy: 0.9240 - val_loss: 0.2552 - val_accuracy: 0.9093\n",
            "Epoch 6/30\n",
            "329/329 [==============================] - 15s 44ms/step - loss: 0.1916 - accuracy: 0.9285 - val_loss: 0.2303 - val_accuracy: 0.9225\n",
            "Epoch 7/30\n",
            "329/329 [==============================] - 16s 48ms/step - loss: 0.1702 - accuracy: 0.9372 - val_loss: 0.2359 - val_accuracy: 0.9194\n",
            "Epoch 8/30\n",
            "329/329 [==============================] - 16s 48ms/step - loss: 0.1553 - accuracy: 0.9425 - val_loss: 0.2240 - val_accuracy: 0.9294\n",
            "Epoch 9/30\n",
            "329/329 [==============================] - 15s 45ms/step - loss: 0.1376 - accuracy: 0.9489 - val_loss: 0.2175 - val_accuracy: 0.9307\n",
            "Epoch 10/30\n",
            "329/329 [==============================] - 16s 47ms/step - loss: 0.1274 - accuracy: 0.9528 - val_loss: 0.2522 - val_accuracy: 0.9258\n",
            "Epoch 11/30\n",
            "329/329 [==============================] - 15s 44ms/step - loss: 0.1179 - accuracy: 0.9562 - val_loss: 0.2718 - val_accuracy: 0.9264\n",
            "Epoch 12/30\n",
            "329/329 [==============================] - 16s 48ms/step - loss: 0.1098 - accuracy: 0.9579 - val_loss: 0.2339 - val_accuracy: 0.9276\n",
            "Epoch 13/30\n",
            "329/329 [==============================] - 16s 48ms/step - loss: 0.0974 - accuracy: 0.9635 - val_loss: 0.2531 - val_accuracy: 0.9296\n",
            "Epoch 14/30\n",
            "329/329 [==============================] - 16s 47ms/step - loss: 0.0872 - accuracy: 0.9685 - val_loss: 0.2523 - val_accuracy: 0.9278\n",
            "Epoch 15/30\n",
            "329/329 [==============================] - 15s 45ms/step - loss: 0.0852 - accuracy: 0.9690 - val_loss: 0.2891 - val_accuracy: 0.9293\n",
            "Epoch 16/30\n",
            "329/329 [==============================] - 16s 47ms/step - loss: 0.0729 - accuracy: 0.9729 - val_loss: 0.2826 - val_accuracy: 0.9314\n",
            "Epoch 17/30\n",
            "329/329 [==============================] - 15s 45ms/step - loss: 0.0748 - accuracy: 0.9731 - val_loss: 0.2798 - val_accuracy: 0.9328\n",
            "Epoch 18/30\n",
            "329/329 [==============================] - 15s 45ms/step - loss: 0.0645 - accuracy: 0.9770 - val_loss: 0.2901 - val_accuracy: 0.9333\n",
            "Epoch 19/30\n",
            "329/329 [==============================] - 15s 45ms/step - loss: 0.0587 - accuracy: 0.9787 - val_loss: 0.3686 - val_accuracy: 0.9274\n",
            "Epoch 20/30\n",
            "329/329 [==============================] - 15s 45ms/step - loss: 0.0551 - accuracy: 0.9811 - val_loss: 0.4256 - val_accuracy: 0.9207\n",
            "Epoch 21/30\n",
            "329/329 [==============================] - 15s 45ms/step - loss: 0.0563 - accuracy: 0.9792 - val_loss: 0.3537 - val_accuracy: 0.9271\n",
            "Epoch 22/30\n",
            "329/329 [==============================] - 16s 47ms/step - loss: 0.0652 - accuracy: 0.9771 - val_loss: 0.2939 - val_accuracy: 0.9336\n",
            "Epoch 23/30\n",
            "329/329 [==============================] - 16s 47ms/step - loss: 0.0456 - accuracy: 0.9832 - val_loss: 0.4142 - val_accuracy: 0.9266\n",
            "Epoch 24/30\n",
            "329/329 [==============================] - 15s 45ms/step - loss: 0.0404 - accuracy: 0.9859 - val_loss: 0.3424 - val_accuracy: 0.9333\n",
            "Epoch 25/30\n",
            "329/329 [==============================] - 16s 47ms/step - loss: 0.0433 - accuracy: 0.9848 - val_loss: 0.3648 - val_accuracy: 0.9290\n",
            "Epoch 26/30\n",
            "329/329 [==============================] - 15s 45ms/step - loss: 0.0456 - accuracy: 0.9842 - val_loss: 0.3646 - val_accuracy: 0.9291\n",
            "Epoch 27/30\n",
            "329/329 [==============================] - 16s 47ms/step - loss: 0.0373 - accuracy: 0.9866 - val_loss: 0.3884 - val_accuracy: 0.9349\n",
            "Epoch 28/30\n",
            "329/329 [==============================] - 16s 47ms/step - loss: 0.0344 - accuracy: 0.9882 - val_loss: 0.4169 - val_accuracy: 0.9246\n",
            "Epoch 29/30\n",
            "329/329 [==============================] - 16s 47ms/step - loss: 0.0363 - accuracy: 0.9875 - val_loss: 0.4176 - val_accuracy: 0.9263\n",
            "Epoch 30/30\n",
            "329/329 [==============================] - 16s 47ms/step - loss: 0.0395 - accuracy: 0.9868 - val_loss: 0.3822 - val_accuracy: 0.9348\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7fe3b732f0d0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "model.fit(x_train, y_train, batch_size=128, epochs=30, verbose=1, validation_split=0.3, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model's evaluation and prediction exercise.\n",
        "\n",
        "The model is evaluated with the test set. The last epoch of training returned an accuracy of 93.48% which is\n",
        "\n",
        "At the end there is a small prediction exercise for one sample."
      ],
      "metadata": {
        "id": "MM2e1tKKz0pC"
      },
      "id": "MM2e1tKKz0pC"
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x=x_test, y=y_test)"
      ],
      "metadata": {
        "id": "zEzU0O8n2rp2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d04d1043-ecb8-4b74-d603-dfda57de9eca"
      },
      "id": "zEzU0O8n2rp2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 5ms/step - loss: 0.4633 - accuracy: 0.9263\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4632863700389862, 0.9262999892234802]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_test = np.random.randint(0, x_test.shape[0])"
      ],
      "metadata": {
        "id": "JMepmCtJ2sTq"
      },
      "id": "JMepmCtJ2sTq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.shape(x_test[sample_test])"
      ],
      "metadata": {
        "id": "oX1X5KqU2sWB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3c91eaf-89e9-463b-c3a4-759aba5d00a3"
      },
      "id": "oX1X5KqU2sWB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.shape(x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ubj9xHTb4PAD",
        "outputId": "62035a2b-904e-4fb3-dbad-7eead1a062a3"
      },
      "id": "Ubj9xHTb4PAD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = x_test[sample_test]"
      ],
      "metadata": {
        "id": "ArbvtcsJ2sYX"
      },
      "id": "ArbvtcsJ2sYX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.shape(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAxQmiTp4ect",
        "outputId": "2e916cb6-78a5-4e36-af76-e8e2c3ef6b35"
      },
      "id": "wAxQmiTp4ect",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = x_test[sample_test].reshape(1,28,28)"
      ],
      "metadata": {
        "id": "Tq001DWy4dCw"
      },
      "id": "Tq001DWy4dCw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.shape(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-SSA7Nw4k3m",
        "outputId": "f55e130e-36f6-405a-92cf-7e5983b54158"
      },
      "id": "W-SSA7Nw4k3m",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "560f9e5b",
      "metadata": {
        "id": "560f9e5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65f413e1-5cd0-4df5-d7bb-fd3fc851e7a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 186ms/step\n"
          ]
        }
      ],
      "source": [
        "result= model.predict(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e0d0822",
      "metadata": {
        "id": "5e0d0822"
      },
      "outputs": [],
      "source": [
        "prediction= result.argmax()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_classes[prediction]"
      ],
      "metadata": {
        "id": "k5VjNpsb23of",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5e9b5115-64e3-4590-96dd-10df88524d4c"
      },
      "id": "k5VjNpsb23of",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Shirt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(mnist_classes[y_test[sample_test]])"
      ],
      "metadata": {
        "id": "_8Klmm5z231T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e6628f6-68de-401f-c4a9-4b4b54b43bee"
      },
      "id": "_8Klmm5z231T",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shirt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = x_test.reshape(10000, 28, 28).astype('float32')\n",
        "plt.figure(figsize = (2,2))\n",
        "mnist_img = x_test[sample_test]\n",
        "plt.imshow(mnist_img,cmap=\"Greys\")\n",
        "ax = plt.gca()"
      ],
      "metadata": {
        "id": "6KsIBkCa27ep",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "40b40bf2-4d03-4d55-d1ff-4b22b257d7c2"
      },
      "id": "6KsIBkCa27ep",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 200x200 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusion.\n",
        "\n",
        "The convolution model definitely surpass a full-dense model because it can captures features while maitining the 2 dimensional shape of the image."
      ],
      "metadata": {
        "id": "UhwPZbIQ3AQH"
      },
      "id": "UhwPZbIQ3AQH"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}